Chat Bot using Python and OpenAI

This project is a simple command-line chatbot built with Python.
It communicates with the OpenAI API or an offline model based on Ollama, depending on your setup.

The chatbot accepts user input in the terminal and returns responses generated by the selected model.

Features

Conversational interface in the terminal

Supports both online (OpenAI API) and offline (Ollama) models

Clean and minimal code structure

Easy to configure and run

Requirements

Install required packages:

pip install openai python-dotenv


If you want to use offline mode:

Install Ollama from https://ollama.com/download

Pull a model:

ollama pull llama3.1

Environment Setup

Do not hard-code API keys inside the source code.

Create a .env file:

OPENAI_API_KEY=your_api_key_here


Load it in your Python script:

from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

Usage

Run the chatbot:

python chatbot.py


Type your message and press Enter.
To exit, type:

quit
exit
bye

Online Mode (OpenAI API)

Example structure:

from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def chat_with_gpt(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message["content"].strip()

Offline Mode (Ollama)

Example structure:

import subprocess

def chat_with_llama(prompt):
    process = subprocess.Popen(
        ["ollama", "run", "llama3.1"],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        text=True
    )
    output, _ = process.communicate(prompt)
    return output.strip()

Project Structure
project/
│
├── chatbot.py
├── README.md
├── .env
└── requirements.txt

Security Notes

Never commit API keys to Git repositories.

Always use environment variables for secrets.

If a key is pushed accidentally, delete the key and replace it immediately.
